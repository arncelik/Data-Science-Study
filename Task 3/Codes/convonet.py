# -*- coding: utf-8 -*-
"""Convonet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JK6eXypNwA7vYpIeOlJxNnHUq6ECPI1-
"""



from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.model_selection import train_test_split
from sklearn.datasets import load_iris
import argparse

#constrcut the argument parser and parse the argument
ap = argparse.ArgumentParser()
ap.add_argument("-m", "--model", type=str, default='knn',
               help="type of python machine learning model to use")
args = vars(ap.parse_args())

# %tb

# define the dictionary of models our script can use, where the key 
# to the dictionary is the name of the model(supplied via command line argument) 
# and the value is the model itself
models = {
    "knn": KNeighborsClassifier(n_neighbors=1),
    "naive_bayes": GaussainNB(),
    "logit":LogisticRegression(solver="lbfgs", multi_class="auto"),
    "svm": SVC(kernel="rbf", gamma="auto"),
    "decison_tree": DecisionTreeClassifier(),
    "random_forest": RandomForestClassifier(n_estimators=100),
    "mlp":MLPClassifier()
}

python claaify_irs.py --model knn

#load th eIris dataset and perform a trainign and testign split,
# using 75% of the data for training and 25% for evaluation
print("[INFO] loading data...")
dataset = load_iris()
(trainX, testX, trainY, testY) = train_test_split(dataset.data,
 dataset.target, random_state=3, test_size=0.25)

# train the model
print("[INFO] using '{}' model".format(args["model"]))
model = models[args["model"]]
model.fit(trainX, trainY)

#make predictions = model.predict(testX)
predictions = model.predict(testX)
print(classification_report(testY, predictions,
                           target_names=dataset.target_names))

#import the necessary libraries
from sklearn.neighbors import KNeigborsClassifier
from sklearn.naive_bayes import GaussainNB
from skelarn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.preprocresing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from PIL import Image
from imutils import paths
import numpy as np
import argparse
import os

def extract_color_stats(image):
  #split the input image into its respective RGB color channels 
  #and then create a feature veector with 6values: the mean and 
  #standart deviation for each of the 3 channels, respectively
  (R, G, B)=image.split()
  features = [np.mean(R), np,mean(G), np.mean(B), np.std(R),
             np.std(G), np.std(B)]
  #returning our set of feature
  return features

# grab all image paths in the input dataset directory, initialize 
# our list of extracted features and correspondong labels
print ("[INFO] extracting image features..")
imagePaths = paths.list_images(args["dataset"])
data = []
labels = []

#loop over our input images
for imagePaths in imagePaths:
  # load the input image from disk, compute color channel
  # statistics, and then update our data list
  image = Image.open(imagePath)
  features = extract_color_stats(image)
  data.append(features)
  
  #extract teh class label from the file path and update the 
  # label list
  label = imagePath.split(os.path.sep)[-2]
  labels.append(label)

# encode the labels, converting tehm from strings to integers
le = LableEncoder()
labels = le.fit_transform(labels)

#perform a training and testing split, using 75% of the data for 
# training and 25% for evaluation
(trainX, testX, trainY, testY) = train_test_split(data, labels
test_size=0.25)

(pdb) labels = le.fit_transform(labels)
(pdb) set(labels)
{0, 1, 2}

# train the model
print("[INFO] using '{}' model".format(args["model"]))
model = modes[args["model"]]
model.fit(trainX, trainY)

#make predictions on our data and show a classification report 
print("[INFO] evaluating...:D")
prediction = model.predict(testX)
print(classification_report(testY, predictins,
      target_names=le.classes_))

